# Deep Learning Week 5: GANs

## 1. Brief description of the problem and data

In this week's assignment, we will participate in the Kaggle competition [I’m Something of a Painter Myself](https://www.kaggle.com/competitions/gan-getting-started), which challenges participants to build generative adversarial models (GANs) that can generate images of artworks that resemble images of famous painters like Monet.

### Dataset Description
The dataset contains four directories: monet_tfrec, photo_tfrec, monet_jpg, and photo_jpg. The monet_tfrec and monet_jpg directories contain the same painting images, and the photo_tfrec and photo_jpg directories contain the same photos.

- The monet directories contain Monet paintings. These images are used to train our GAN models.
- The photo directories contain photos. These photos are used to generate images for submission.

**Files**
- monet_jpg - 300 Monet paintings sized 256x256 in JPEG format
- monet_tfrec - 300 Monet paintings sized 256x256 in TFRecord format
- photo_jpg - 7028 photos sized 256x256 in JPEG format
- photo_tfrec - 7028 photos sized 256x256 in TFRecord format

**Submission Format**
- The submision must be named as images.zip and contain 7,000-10,000 generated images sized 256x256.

**Evaluation**
- Submissions are evaluated on MiFID (Memorization-informed Fréchet Inception Distance), which is a modification from [Fréchet Inception Distance (FID)](https://arxiv.org/abs/1706.08500).

### Generative Adversarial Networks (GANs):

A Generative Adversarial Network (GAN) is a type of deep learning model that is capable of generating new data that shares the same characteristics as a given training dataset. This is achieved through an adversarial process involving two neural networks: a Generator and a Discriminator, which compete against each other in a zero-sum game.

**Generator (G)**: The role of the Generator is to create fake data such as images, text, etc. that looks as real as possible. It usually takes a random noise vector that acts as a seed for the generation process as input, from which it generates synthetic data samples. The the Generator tries to fool the Discriminator by generating fake data that is so realistic that the Discriminator cannot tell the difference.

**Discriminator (D)**: In contrast to the Generator, the Discriminator acts as a binary classifier. It tries to determine whether the input data is real data (from the actual training data set) or fake data (generated by the Generator). It tries to not be fooled by the Generator

**GAN Training Process:**

Generator Training: The Generator generates a batch of fake samples from random noise, which are then fed to the Discriminator. The output of the Discriminator is used to calculate the Generator's loss and update its parameters to make its generated samples appear more realistic to the Discriminator.

Discriminator Training: The Discriminator is given a set of real data samples from the training dataset and a set of fake data samples generated by the Generator. It classifies both real and fake samples. The Discriminator loss is calculated based on how accurately it classifies real samples as real samples and fake samples as fake samples. The Discriminator parameters are updated to improve its ability to distinguish between real and fake data.

As the training progresses, The Generator gets better and better at generating highly realistic samples. The Discriminator gets better and better at identifying subtle differences between real and fake data, forcing the Generator to improve further. This process eventually leads to a state where the Generator can generate data that is virtually indistinguishable from real data and the Discriminator can no longer tell the difference.

### Cycle-Consistent Generative Adversarial Network(CycleGAN):

CycleGAN (Cycle-Consistent Generative Adversarial Network) is an advanced type of Generative Adversarial Network (GAN) specifically designed for unpaired image-to-image translation. Traditional image-to-image translation tasks (e.g., converting a summer photo to a winter photo of the same scene) typically require paired training data. This means that for every input image in domain A (e.g., a summer photo), we need a corresponding output image in domain B (e.g., a winter photo). With CycleGAN, we do not need paired training data because CycleGAN can learn the mapping between two image domains without paired data samples. CycleGAN is a powerful solution for learning domain-to-domain image translation when we have large collections of images from two different domains, but no direct mapping between them.

CycleGAN uses not one but two generators and two discriminators to enforce the cycle consistency constraint:

**Two Generators:**

G: X → Y: A generator that translates images from domain X to domain Y (e.g., summer photo to winter photo).

F: Y → X: Another generator that translates images from domain Y back to domain X (e.g., winter photo to summer photo).

**Two Discriminators:**

D_Y: Discriminates between real images from domain Y and fake images generated by G(X).

D_X: Discriminates between real images from domain X and fake images generated by F(Y).

**The Cycle Consistency Loss:** This is what makes unpaired training possible. The idea is that if we translate an image from domain X to domain Y using G, and then translate that generated image back to domain X using F, we should get back something very close to our original image. This forms a "cycle":

Forward Cycle Consistency: X→G(X)→F(G(X))≈X

Backward Cycle Consistency: Y→F(Y)→G(F(Y))≈Y

This loss function pushes the generators to find a meaningful, reversible mapping between the domains, preventing them from simply mapping all inputs to a single output or generating unrelated images. It acts as a strong regularization term.

### Model Selection:

We'll choose CyCleGAN to solve this challenge because this challenge requires us to build a GAN network to generate 7,000 to 10,000 images from a set of 300 Monet paintings and about 7,000 photos, so the CycleGAN model is a good choice for this kind of unpaired image-to-image translation problem.

### Summary of Tasks:
- Load monet photo dataset
- Explore the dataset, perform data cleaning, data analysis, preprocess image data
- Build and test models: Build, evaluate, and our GAN models (CycleGAN). 
- Summarize and discuss the results.
